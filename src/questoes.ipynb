{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O conjunto de dados do Birmighan parking se apresenta como uma base de dados de estacionamento com as seguintes variáveis: código do estacionamento, capacidade do estacionamento, ocupação e data de atualização.\n",
    "O que se entende é que os dados independentes neste caso são o código, capacidade e data e a variável dependente seria a ocupação que é um valor inteiro.\n",
    "No caso do desfecho de ocupação, ele deve ser convertido de um valor absoluto para um valor relativo, no caso, o percentual de ocupação. A partir deste percentual e avaliação das possíveis categorias e seus balanecemanetos, decidi dividir em quatro subconjuntos: Vazio, Meio-Vazio, Meio-Cheio e Cheio. Estas seriam as possíveis classificações do modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso dos atributos de valor devem ser feitos os seguintes processamentos:\n",
    "O código de estacionamento deverá ser \"dumizado\" para ser utilizado no modelo. O atributo de capacidade será mantido da mesma forma. O atributo de data deverá ser transformado em vários valores de séries temporais, incluindo hora, dia da semana, dia de trabalho x dia de fim de semana, mês, e a própria data convertida para dtype data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apresentado no jupyter notebook de python. \n",
    "Distribuição dos dados: \n",
    "Half-Empty    10107\n",
    "Half-Full      9131\n",
    "Empty          8520\n",
    "Full           7341\n",
    "Erro marjoritário: 28.79%\n",
    "Foi utilizado o excel para uma visão inicial do dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plano de Execução:\n",
    "- Importação das bibliotecas\n",
    "- Importação do dataset\n",
    "- Tratamento dos dados\n",
    "- Análise exploratória\n",
    "- Regressão linear multivariada\n",
    "- Cross-validation\n",
    "- Utilização do Modelo SVM para classificação\n",
    "- Apresentação dos resultados e acurácia\n",
    "Foram utilizadas as bibliotecas mais importantes para datascience em python, incluindo numpy, matplotlib, pandas, sklearn, seaborn, datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foi utilizado o python como ferramenta principalde análise com o uso do jupyter notebook rodando em um ambiente de execução do miniconda\n",
    "O dataset tinha inicialmente 35717 registros e após a limpeza dos dados ficou com 35099 registros com uma perda de 1,7% dos dados\n",
    "Foi selecionado o Supporte Vector Machine para análise do modelo\n",
    "Para ajuste dos hiperparâmetros foi feita uma validação cruzada da seguinte forma:\n",
    "Separação de um conjunto 20% de teste para avaliação final do modelo\n",
    "Os 80% restantes foram ajustados em um grid search para busca do melhor hiperparametro para o C (Que no caso é inversamente proporcional aos pontos buscados no vetor) e foi utilizado o kernel 'rbf', C =10 e gamma=0.001. A busca exaustiva destes hiperparametros consumiu aproximadamente 2min em uma máquina i7 com 8gb de memória.\n",
    "Por fim, o teste apresentou os seguintes resultados:\n",
    "Os resultados de acurácia e f1-score foram 1.0\n",
    "As médias de acurácia do k_fold também foram de 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim. O modelo de SVM tem um custo maior para execução do ajuste do modelo, mas é bem mais confiável depois dos resultados obtidos. Um avanço do modelo seria utilizar georeferenciamento para achar o estacionamento mais próximo e que esteja com menos de 50% de ocupação. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O SVM a princípio pode utilizar o kernel linear e separar o modleo linearmente tendendo a ter uma melhor explicabilidade e não necessitando de maiores complexidades. Já a forest-tree permite explorar melhor modelos não-lineares, sendo que sua representação é melhor explicável por ser mais intuitiva. Porém, dependendo do número de feat pode ser difícil utilizar a árvore de decisão. O SVM pode utilizar outras kernel, em vetores mais complexos, porém com uma perda importante de explicabilidade."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Erro marjoritario de 89% (800/900). Poderia ser feita de forma estratificada ou com oversampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Erro marj 55% (25/45). Poderia ser feita de forma aleatória com penalização da classe maior"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 9"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entendo que para esse requisito funcional seria necessário algum nível de knowledge translation, o modelo preditivo poderia ser utilizado em alguma api de microsserviço conectada ao sistema, em que a saída do classificador da RN poderia acompanhar a análise de sensibilidade (na forma de gráfico, acho intuitivo um tornado plot), demonstração dos pesos das funções, um linguagem simplificada  e uma contextualização dos resultados obtidos. Algumas métricas de retorno do modelo poderiam ser enviadas e acompanhadas de uma explicação. Acredito que há uma maturidade de bibliotecas em js que poderiam otimizar a entrada e saída destas informações que fiquem integradas à api que rodaria o modelo. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
